\documentclass[11pt]{article}
\usepackage{xcolor}
\usepackage[T1]{fontenc}
\usepackage{inconsolata}
\usepackage{listings}
\usepackage{graphicx}
\usepackage[backend=biber,
style=alphabetic,
citestyle=authoryear]{biblatex} %Imports biblatex package

\addbibresource{references.bib}
\graphicspath{ {./imgs/} }

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\usepackage[font={color=codegray},figurename=Figure,labelfont={it}]{caption}

\lstset
{ %Formatting for code in appendix
    language=C,
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    numbers=left,
    stepnumber=1,
    showstringspaces=false,
    tabsize=1,
    breaklines=true,
    breakatwhitespace=false,
}

\newcommand{\code}[1]{{\colorbox{lightgray!15}{\color{black}\texttt{#1}}}}
\newcommand{\temp}[1]{{\color{red}#1}}
\newcommand{\centeredpic}[4][0.5]{
    \begin{figure}[h]
        \includegraphics[scale=#1]{#2}
        \centering
        \caption{#3}
        \label{fig:#4}
    \end{figure}
}

\begin{document}
\begin{titlepage}
    \begin{center}
        \huge
        \textbf{Operating systems and C}

        \vspace{0.5cm}
        Exam answers

        \vspace{3cm}
        \includegraphics[width=0.6\textwidth]{itu.jpeg}

        \vspace{3cm}
        \large
        Andreas Nicolaj Tietgen 
        
        anti@itu.dk

        \vfill
        16. Dec 2022
    \end{center}
\end{titlepage}

\newpage

\tableofcontents

\newpage
\section{Data lab}

\subsection{Describe your implementation of \code{howManyBits(x)}}
Sadly I did not make this in time before the hand-in deadline. However, I have figured a way to 
solve the problem. The idea is to perform a binary search for the most significant active bit.
The issue is that we also need to do this for negative numbers where the sign bit is active. In order to 
solve this we then take the bitwise negation of x. Doing so leaves us with a number that is one short of being the
actual absolute value. However, the reason for that is to avoid overflowing to a negative number again. 
When the binary search is finished, we then add 1 to the result in order to take the signed bit into account.

Lets make a walkthrough. We have \code{x = 0xA0FFF0F0} which is a negative number.
We find out that it is a negative number by looking at the signed bit. We then take the
logical negation of the number so that x is now \code{0x5f000f0f}. 
Now what we want to do is to figure out where the most significant active bit is. As mentioned before,
it can be found by performing binary search. 

So we start from the middle:

\centeredpic{howmanybits-01.png}{Bit representation of the negated integer of \code{x}}{hmb-step-1}

We look to the left and check if there is at least 1 bit that is active(i,e, a bit with the value 1). In figure \ref{fig:hmb-step-1}, there is a bit that is active.
For now, we can with confidence say that we at least need 16 bits in order to represent this number.

The following code provides the same result:
\begin{lstlisting}
    int active_bits_left = !!(temp >> 16);
    min_required_bits = active_bits_left << 4;
    
    /* 
    * Shift the result such that we can continue the search for the 
    * last active bit 
    */
    temp >>= min_required_bits;
    result += min_required_bits; // Store the min required bits
\end{lstlisting}

The \code{!!(temp >> 16)} looks at the left half of the bit representation and returns 1 if there is an active bit and 0 if not. We then bit shift it by 4 in order to get the amount of bits 
that we can guarantee that is required to represent the integer. 

At line 8 we bit shift the \code{min\_required\_bits}, i.e. 16 in this case, such that we can continue our search. The result looks like the following:
\centeredpic{howmanybits-02.png}{The bit representation of temp after bits shifting it. Grey blocks, have been bit shifted out}{hmb-step-2}

As figure \ref{fig:hmb-step-2} shows, we now continue the process of binary search and take the half again. Again we can see that there is
a bit on the left side of line. This guarantee that we now at least need 8 bits on top of the previous 16 bits that we have, i.e. 24.

The code to perform this looks nearly the same as in figure \ref{fig:hmb-step-1}:
\begin{lstlisting}
    int active_bits_left !!(temp >> 8);
    min_required_bits =  active_bits_left << 3;

    /* 
    * Shift the result such that we can continue the search for the 
    * last active bit 
    */
    temp >>= min_required_bits;
    result += min_required_bits; // Store the min required bits
\end{lstlisting}

The difference is at line 1 and 2. At line 1 we half the amount of bits that we want to bit-shift with at each step until it reaches zero. And at line 2 we decrement the 
amount of bits we bit shift the result of the \code{active\_bits\_left} by one at each step until it reaches zero. 
Another things to notice as well is that we continue to add the minimum required bits that we bit-shift out of the \code{temp} at each step.
The following figure is an illustration of continuing the steps describe: 
\centeredpic{howmanybits-03.png}{An illustration of the continuation of the same steps. The gray blocks have been bit-shited out}{hmb-step-last}

Before the last step of figure \ref{fig:hmb-step-last}, the minimum required bits is 30. The last step is a bit different. The left side of the line does not have an active bit.
For that reason, the variable \code{minimum\_required\_bits} is 0 and we do not bit shift.
The process of performing binary search is done. However we still need to add the result of \code{temp}. Because if the bit on the right side of line is active, then that needs to be added.
Due to our binary search and bit-shifting of the binary representation of the integer, then we only add 1 or 0 to our result. 
Before we return the result, we need to add the sign bit. For that reason we add 1 to the result. We return a result of 32 minimum required bits to represent \code{0xA0FFF0F0}.

\subsection{Describe your implementation of \code{tmin(void)}}
The \code{tmin()} task was about creating the minimum number in a two complement bit representation.
Two's complement uses the most significant bit as a sign bit. That is, the bit at the left most position indicates whether 
it is a negative or positive number. If the bit is 1 then the number is a minus. 
In terms of how the minimum number is represented in a two's complement system then it is by having the first bit set to 1 and then rest of the bits set to 0.
In a 32 bit system then it would look like the following:

\begin{figure}[h]
    $1000 \; 0000 \; 0000 \; 0000 \; 0000 \; 0000 \; 0000 \; 0000_2 = -2147483648_{10}$
    \centering
\end{figure}


Following the set of rules for the assignment, it is solved by having a constant which is \code{0x01}
and then bit-shift by 31 positions like the following:
\begin{lstlisting}
    int tmin() {
        return 0x01 << 31;
    }
\end{lstlisting}


\section{Perf lab}

\subsection{A. What is the difference between spatial and temporal locality}
\textit{Spatial locality} is when we access something in memory then it is likely that we reference some of the nearby addresses some time after. An example is
when we loop through arrays. Then we take the next element each time.
\begin{lstlisting}
void print_items(int a[N]) {

    for(int i = 0; i < N; i++) {
        printf("%d \n", a[i]);
    }
}
\end{lstlisting}
As can be seen above, the loop goes through the elements of array, by accessing it one by one. Here we get elements 
by utilizing how the array structure the data. \textit{Temporal locality} is when an item that is being reference is likely to be 
referenced again in the near future. An example of that is when we create a temporal locality is when we reference a specific variable
at each iteration.
\begin{lstlisting}
int pow(int a, int pow) {
    int tmp = a;

    for(int i = 0; i < pow; i++) {
        tmp = tmp * a;
    }

    return tmp;
}
\end{lstlisting}
When \textit{Spatial} or \textit{temporal locality} the cache is being used. This is very important in terms of performance.
We use the cache to get data that we need for our application fast. The difference between main memory and the L1 cache is around 100 clock cycles.
So by utilizing locality we limit the cache misses and help our applications to utilize the cache better making our applications perform better.

\subsection{B. What is SIMD processing}
SIMD, also known as \textit{Single Instruction Multiple Data}, is a way to perform computations on a lot of data
with one instruction. The way that it works is by defining a vector with the data that we want to perform computations
upon using the \textit{AVX} library. The \textit{AVX} library contains functions that ensures that we perform the computation 
with one single instruction. 

My solution does not utilize SIMD. That is due to not using vectors that we can perform arithmetic operations upon. However, the smooth
solution could have benefitted from it in the cases where we need to take the average of $3 * 3$ pixel. Here we could have created a accumulator vector
and a vector for each row and use the \code{+} between the accumulator and the row. Afterwards we can add each value in the accumulator vector and divide it by nine.
This will lead to removing 3 add instructions in the \code{avg\_smooth} function making it more performant.

\section{Malloc lab}
\subsection{Explain in detail your implementation of the \code{mm\_malloc} function}
\centeredpic[0.4]{Allocation blocks.png}{Show how an allocated and free block is structured}{blocks}
In order to understand the implementation of \code{mm\_malloc()}, then we have to understand how we keep track of the free memory blocks that we have.
In figure \ref{fig:blocks} is a representation of the an allocated and a free block. The header and footer contains the same data i.e., the size and a flag indicating if it is allocated or not.
The difference between the allocated and the free block is that, we have a previous free block pointer and a next free block pointer. We use these pointers,
to link our free blocks together into an \textit{explicit free list}(See figure \ref{fig:explicit-list}).
\centeredpic[0.4]{Explicit free list.png}{shows explicit free list is structured}{explicit-list}
The explicit free list only points to free blocks. For that reason, we use the previous and next free block pointers to create a linked list. 
When we insert a new block to the free list, we insert it at the beginning. We set the free pointers such that the new element points with the next pointer to the previously first free block in the list and by making the previously
first free block setting the previous free block pointer to point to the new free block.

However, the implementation of the explicit free list contains every free block unordered in size. The potential running time of getting an
element that is equal or greater than the size we want could be $O(n)$ where $n$ is the number of free blocks in the explicit free list.
For that reason, I have implemented segregated free list. As figure \ref{fig:segregated-list} shows then it consists of an array of pointers to 
explicit free lists. The entries of explicit lists only contains particular sizes. 
\centeredpic[0.3]{Segregated free list.png}{Segregated free lists consist of an array of explicit free lists, where the explicit free list have its own equivalence class}{segregated-list}
This allows us to skip free blocks that are too small and look in the explicit free lists that could have a free block that fits in size.

The implementation of the \code{mm\_malloc()} function, is the same as the books implementation(\cite[ch. 9.9.12]{csapp-mem}).
It first checks the requested \code{size}. The first check is to see if the size is equal to 0. If that is the case, we have to return \code{NULL}.
Afterwards, we have to adjust the variable \code{size} to be aligned to 8 and save it to a variable called \code{asize}. 
There are two cases that needs to be taken care of:
\begin{itemize}
    \item When the requested size is below or equal the constant \code{DSIZE}: We set the adjusted size, i.e. \code{asize}, to $2 * DSIZE$.
    \item When the requested size is above the constant \code{DSIZE}: We use the \code{ALIGN()} macro with $size + DSIZE$ as an argument. We add \code{DSIZE} to the size as input
    in \code{ALIGN()} to ensure that we have space for the header and footer.
\end{itemize}

After adjusting the size, we use the \code{find\_fit()} function to find a free block that can contain the adjusted size, \code{asize}. If it returns \code{NULL} then we need to extend the
heap. 
Now that we have a free block then we need to allocate it. 
\code{place()} takes care of allocating the free block, and returns a pointer to the allocated block.

\subsubsection{\code{find\_fit()}}

The \code{find\_fit()} utilizes the segregated free list implementation.
This can be seen in figure \ref{fig:get-list-index} where it gets the index of the first list that could contain the size being requested.
\begin{figure}[h]
    \code{int index = get\_free\_list\_index(size);}
    \centering
    \caption{Shows Line 4 in appendix \ref{appendix:find_fit}}
    \label{fig:get-list-index}
\end{figure}
This ensures that we skip the lists that does not contain sizes that fits the requested size. The index serves as a starting point
of where to look for a free block. The function goes through each explicit free list from the starting point(see line 6-8 in appendix \ref{appendix:find_fit}).
Due to the first fit implementation it will stop as soon as it finds a free block that fits the requested size. 
If the current list, that we go through, points to \code{NULL} or does not have a block that fits, we increment the index by 1 and get the next list.
If \code{find\_fit()} is not able to find a free block that fits, it will then return \code{NULL}.

\subsubsection{\code{place()}}
Before \code{place()} starts allocating the free block, it first calculate the difference in size between the size of the free block and the requested and store the result in a variable \code{size\_diff}.
Afterwards it removes the free block from the free list by calling the \code{remove\_free\_block()} function. We do so to ensure that the free block we want to allocate, 
is not going to be present in the free list anymore. Now that it is removed, the function then decides whether we should split the block which we want to allocate. 
\code{place()} is going to split if the variable \code{size\_diff} is greater than $2 * DSIZE$.
We need it to be greater than $2 * DSIZE$ such that we have place for the header, footer, next pointer, and previous pointer. 

If the function decides to split then it does the following(see line 26-32 in appendix \ref{appendix:place}): 
\begin{itemize}
    \item Sets the header and footer of the block we want to allocate, by setting the size to be equal to the \code{asize} and allocation tag to be 1.
    \item We then jump to the next free block, with \code{NEXT\_BLKP} and sets the header and footer to be the size to \code{size\_diff} and the allocation tag to 0, i.e. free.
    \item Lastly it adds the new free block to the free list with the function \code{insert\_free\_block}.
\end{itemize}

If the \code{place()} function decides not to split, it then allocates the free block by setting the header and footer with a size that it already had an the allocation flag to be allocated like the following code:
\begin{lstlisting}
PUT(HDRP(bp), PACK(size, 1));
PUT(FTRP(bp), PACK(size, 1)); 
\end{lstlisting}

\subsection{What is pointer arithmetic?}
Pointer arithmetics are a way to move the pointer to another virtual memory address. The special thing to remember is that the amount of bytes 
that the address moves is depending on which type of pointer it is e.g. \code{char}, \code{integer}, \code{long}, and etc.
\centeredpic{pointer arithmetic.png}{Show the difference when adding n to a pointer of a specific type. Each block represents one byte. When adding 1 to a char pointer it moves only by one byte. When adding 1 to an int pointer it moves by 4.}{pointer-arith}
As figure \ref{fig:pointer-arith} shows, in a 64-bit word system, an \code{int*} called \code{int\_p} and a \code{char*} called \code{char\_p} would move at their own respective data-size.
That means that \code{int\_p+1} would move 4 bytes, whereas the \code{long\_p+1} would move 1 byte.
That is also why that in malloc lab, in order to move a pointer only 1 byte we then cast the pointer as a char and add one just like: 
\begin{figure}
    \code{HDRP(bp) ((char *)bp - WSIZE)}
    \centering
\end{figure}

\section{Topics from the class}

\subsection{A. What is the difference between traps, faults and aborts in the context of interrupts?}
Traps, faults and aborts are different exceptions that happens in an operating system.

A \textit{trap} is an intentional exception. What happens is that a system call trigger the \textit{trap} and passes control 
to an exception handler. The exception handler then handles the trap and returns to the instruction that is after the system call.
\textit{Traps} are typically used for calls that request services from the kernel. This could be reading a file with the system call \code{read}
or creating a new process with \code{fork}.

A \textit{fault} happens when an instruction causes an error. When this occurs, it then passes control to an exception handler for that specific fault.
Here two things can happen. The exception handler can handle the fault and give back control to the application by re-executing the instruction. 
It could also choose to abort instead and terminate the application that caused the fault.

An \textit{abort} is when the function reaches a fatal error. Again, we pass control to an exception handler.
However, the exception handler does not try to repair the situation. The handler instead it is being sent to the abort routine 
never giving control back to the application.

\subsection{B. What is the difference between an ephemeral and a well-known port?}
The ephemeral ports are something that is being assigned automatically by kernel of the client. The operating system has a predefined range of ports that it uses to automatically provide a port when a client application wants to communicate through. 
Where as well known ports are typically assigned with some service and has been 
agreed upon by the community. As an example the port 80 is a well known port for the \textit{http} protocol.

\subsection{C. What is a memory leak?}
A memory leak is when something is allocated that is never cleaned up while the application is running. 
It is a lethal thing for an application to occur. This normally happens when we allocate some data in the heap
by using \code{malloc}, from the standard library, and forgets to use the function \code{free} to clean up the memory
at that specific location.

\begin{lstlisting}
    int do_something() {
        int *numbers_p = malloc(sizeof(int)*10);

        // Init numbers
        for(int i = 0; i < 10; i++) {

            numbers_p[i] = i + 1;
        }

        int sum = get_sum(numbers_p, 10);
        
        return sum;
    }

    int get_sum(int *numbers, int count) {
        int sum = 0;

        for(int i = 0; i < count; i++) {

            sum += numbers[i];
        }

        return sum;
    }
\end{lstlisting}
We can see from the above code that we allocated 10 integers in the heap and initialize them 
to $1, 2, 3 ... 10$. Then the \code{get\_sum()} calculates the sum of all the values and returns it.
At the end of function \code{do\_something()} it returns the \code{sum} value. However, the \code{numbers\_p}
still remains in the heap since we have not called the \code{free()} function.

When you have a memory leak in your application then it indicates that it forgets to clean up.
In order to avoid memory leak then we need to keep track of what we have allocated and when we would like to clean it up with the function \code{free()}.

\subsection{D. What is a race-condition?}
A race condition can happen when two concurrent processes changes the same variable at nearly the same time. 
More specifically this can happen because thread A access the variable \code{int a}. Before the thread begins to add 1 then the operating system performs a thread context switch and then thread B reads the same variable and write \code{a + 1} to it.
However, thread A didn't get that changes since before it gave the control to thread B, happen to read the variable before it could add 1 to it. So for that reason the variable is only added by 1 instead of 2 in this example.

This specific scenario can be very hard to debug. But why? Race conditions does not always occur. So if you were to try debug and recreate the example then another example could occur or it might actually work as expected(in that specific run).
We can use the concept of a \textit{mutex} or a \textit{semaphore}. These two provides operations that, if used correctly, can ensure that 
only one thread at a time can access the critical section at a time. 

It is expensive because even though we have a secured the critical section, then all of the threads have to wait until it gets access to
the critical section. They cannot in other words not do any work until it is being let through. This can cause some bottle necks in terms of 
gaining performance if something is taking long time to compute in the critical section.

\newpage
\printbibliography

% Add section for appendix
\newpage
\input{appendix/main-appendix.tex}

\end{document}